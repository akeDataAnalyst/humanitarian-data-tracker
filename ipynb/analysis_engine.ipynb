{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49971dcf-4dec-4d49-bff0-dfadb937928d",
   "metadata": {},
   "source": [
    "#### Setup and Data RetrievalSetup and Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd48afd-723c-4767-9ce0-aa1b66108acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eldu\\AppData\\Local\\Temp\\ipykernel_2824\\2014203858.py:28: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved 8091 clean records from MySQL.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from scipy import stats # Crucial for statistical inference (T-test)\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1. Load Environment Variables and Setup\n",
    "load_dotenv()\n",
    "MYSQL_USER = os.getenv('MYSQL_USER')\n",
    "MYSQL_PASSWORD = os.getenv('MYSQL_PASSWORD')\n",
    "MYSQL_HOST = os.getenv('MYSQL_HOST')\n",
    "MYSQL_DATABASE = os.getenv('MYSQL_DATABASE')\n",
    "\n",
    "def get_clean_data():\n",
    "    \"\"\"Fetches the clean data from the gts_processed_data table.\"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = mysql.connector.connect(\n",
    "            user=MYSQL_USER,\n",
    "            password=MYSQL_PASSWORD,\n",
    "            host=MYSQL_HOST,\n",
    "            database=MYSQL_DATABASE\n",
    "        )\n",
    "        \n",
    "        # Only fetch records marked as valid (is_valid=1) for core analysis\n",
    "        query = \"SELECT * FROM gts_processed_data WHERE is_valid = 1;\" \n",
    "        df = pd.read_sql(query, conn)\n",
    "        \n",
    "        # Ensure scores are integers for accurate calculation\n",
    "        score_cols = ['aid_satisfaction', 'trust_in_aid_provider', 'communication_clarity', 'aid_fairness']\n",
    "        for col in score_cols:\n",
    "             df[col] = df[col].astype(int)\n",
    "             \n",
    "        print(f\"Successfully retrieved {len(df)} clean records from MySQL.\")\n",
    "        return df\n",
    "        \n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Database Error during data fetch: {err}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        if conn and conn.is_connected():\n",
    "            conn.close()\n",
    "\n",
    "df_clean = get_clean_data()\n",
    "\n",
    "if df_clean.empty:\n",
    "    raise RuntimeError(\"Analysis halted: Could not retrieve clean data from the database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14073399-b6d5-4e90-878d-c7efdbb69c00",
   "metadata": {},
   "source": [
    "#### 2.2: KPI Calculation (Descriptive Statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb81f93-286b-4a26-ae34-43be0ef889f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 2.1: KPI Calculation (Descriptive Analysis) ---\n",
      "Total Valid Responses Analyzed: 8091\n",
      "Overall Net Satisfaction Score (NSS): 9.12\n",
      "\n",
      "Mean Scores by Location (Top 5):\n",
      "                               aid_satisfaction  trust_in_aid_provider  \\\n",
      "location                                                                 \n",
      "Cox's Bazar (Bangladesh)                   3.61                   2.82   \n",
      "North-East DRC                             3.59                   2.80   \n",
      "Jigjiga Zone (Ethiopia)                    3.58                   2.77   \n",
      "Darfur Region (Sudan)                      3.57                   2.80   \n",
      "Lviv / Odesa Region (Ukraine)              3.57                   2.79   \n",
      "\n",
      "                               communication_clarity  aid_fairness  \n",
      "location                                                            \n",
      "Cox's Bazar (Bangladesh)                        3.34          3.33  \n",
      "North-East DRC                                  3.38          3.34  \n",
      "Jigjiga Zone (Ethiopia)                         3.37          3.34  \n",
      "Darfur Region (Sudan)                           3.30          3.31  \n",
      "Lviv / Odesa Region (Ukraine)                   3.32          3.28  \n",
      "\n",
      "Mean Scores by Aid Provider:\n",
      "              aid_satisfaction  trust_in_aid_provider  communication_clarity  \\\n",
      "aid_provider                                                                   \n",
      "IRC                       3.57                   2.84                   3.34   \n",
      "NRC                       3.47                   2.83                   3.30   \n",
      "ICRC                      3.59                   2.80                   3.34   \n",
      "UNICEF                    3.60                   2.80                   3.37   \n",
      "WFP                       3.59                   2.78                   3.35   \n",
      "UNHCR                     3.60                   2.77                   3.27   \n",
      "\n",
      "              aid_fairness  \n",
      "aid_provider                \n",
      "IRC                   3.34  \n",
      "NRC                   3.25  \n",
      "ICRC                  3.33  \n",
      "UNICEF                3.27  \n",
      "WFP                   3.34  \n",
      "UNHCR                 3.34  \n"
     ]
    }
   ],
   "source": [
    "# --- 2. KPI Calculation Function (Net Satisfaction Score and Mean Scores) ---\n",
    "\n",
    "def calculate_kpis(df):\n",
    "    \"\"\"\n",
    "    Calculates key descriptive statistics for executive reporting.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Phase 2.1: KPI Calculation (Descriptive Analysis) ---\")\n",
    "    \n",
    "    # --- A. Overall Net Satisfaction Score (NSS) ---\n",
    "    # NSS is derived from Aid Satisfaction (1-5 scale) and is critical for advocacy.\n",
    "    total_responses = len(df)\n",
    "    \n",
    "    # Promoters (Score 5)\n",
    "    promoters = len(df[df['aid_satisfaction'] == 5])\n",
    "    # Detractors (Score 1, 2)\n",
    "    detractors = len(df[df['aid_satisfaction'].isin([1, 2])])\n",
    "    \n",
    "    # NSS = (% Promoters - % Detractors)\n",
    "    nss = round(((promoters / total_responses) - (detractors / total_responses)) * 100, 2)\n",
    "    \n",
    "    print(f\"Total Valid Responses Analyzed: {total_responses}\")\n",
    "    print(f\"Overall Net Satisfaction Score (NSS): {nss}\")\n",
    "    \n",
    "    # --- B. Mean Scores Grouped by Location and Provider ---\n",
    "    \n",
    "    score_cols = ['aid_satisfaction', 'trust_in_aid_provider', 'communication_clarity', 'aid_fairness']\n",
    "    \n",
    "    # Grouped by Location (Shows regional variance)\n",
    "    location_summary = df.groupby('location')[score_cols].mean().round(2).sort_values(by='aid_satisfaction', ascending=False)\n",
    "    print(\"\\nMean Scores by Location (Top 5):\")\n",
    "    print(location_summary.head())\n",
    "    \n",
    "    # Grouped by Provider (Holds partners accountable)\n",
    "    provider_summary = df.groupby('aid_provider')[score_cols].mean().round(2).sort_values(by='trust_in_aid_provider', ascending=False)\n",
    "    print(\"\\nMean Scores by Aid Provider:\")\n",
    "    print(provider_summary)\n",
    "    \n",
    "    return location_summary, provider_summary\n",
    "\n",
    "location_summary, provider_summary = calculate_kpis(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ab3261-5454-4acf-a27d-21a7f05d7e35",
   "metadata": {},
   "source": [
    "#### 2.3: Statistical Significance Testing (Inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b2eeaf6-6323-402b-8bbb-d002ac53347b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Summary of T-Test Results \n",
      "                                   Comparison  Mean_G1  Mean_G2  P_Value  \\\n",
      "0  Female vs. Male (on trust_in_aid_provider)    2.811    2.784  0.38051   \n",
      "1    IDP vs. Host Community (on aid_fairness)    3.328    3.296  0.39126   \n",
      "\n",
      "  Significance  \n",
      "0           No  \n",
      "1           No  \n"
     ]
    }
   ],
   "source": [
    "def check_significance(df):\n",
    "    \"\"\"\n",
    "    Performs T-tests to check if differences in mean scores between key groups \n",
    "    (e.g., Male vs. Female) are statistically significant (P < 0.05).\n",
    "    \"\"\"\n",
    "    \n",
    "    comparison_results = []\n",
    "    \n",
    "    # Comparison 1: Male vs. Female on 'Trust in Aid Provider'\n",
    "    metric = 'trust_in_aid_provider'\n",
    "    group1_name = 'Female'\n",
    "    group2_name = 'Male'\n",
    "    \n",
    "    group1 = df[df['gender'] == group1_name][metric]\n",
    "    group2 = df[df['gender'] == group2_name][metric]\n",
    "    \n",
    "    if len(group1) < 20 or len(group2) < 20:\n",
    "        print(f\"Skipping {group1_name} vs. {group2_name}: insufficient sample size.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Perform Welch's t-test (ttest_ind with equal_var=False) \n",
    "    # This is more robust as it does not assume equal variances between groups.\n",
    "    t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "    \n",
    "    is_significant = p_value < 0.05\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'Comparison': f'{group1_name} vs. {group2_name} (on {metric})',\n",
    "        'Mean_G1': round(group1.mean(), 3),\n",
    "        'Mean_G2': round(group2.mean(), 3),\n",
    "        'Difference': round(group1.mean() - group2.mean(), 3),\n",
    "        'P_Value': round(p_value, 5),\n",
    "        'Significance': 'Yes' if is_significant else 'No'\n",
    "    })\n",
    "    \n",
    "    # --- Comparison 2: IDP vs. Host Community on 'Aid Fairness' ---\n",
    "    metric = 'aid_fairness'\n",
    "    group1_name = 'IDP'\n",
    "    group2_name = 'Host Community'\n",
    "    \n",
    "    group1 = df[df['displacement_status'].str.contains('IDP')][metric] # Use str.contains to catch IDP variations\n",
    "    group2 = df[df['displacement_status'].str.contains('Host Community')][metric]\n",
    "    \n",
    "    if len(group1) < 20 or len(group2) < 20:\n",
    "        print(f\"Skipping {group1_name} vs. {group2_name}: insufficient sample size.\")\n",
    "    else:\n",
    "        t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "        is_significant = p_value < 0.05\n",
    "        \n",
    "        comparison_results.append({\n",
    "            'Comparison': f'{group1_name} vs. {group2_name} (on {metric})',\n",
    "            'Mean_G1': round(group1.mean(), 3),\n",
    "            'Mean_G2': round(group2.mean(), 3),\n",
    "            'Difference': round(group1.mean() - group2.mean(), 3),\n",
    "            'P_Value': round(p_value, 5),\n",
    "            'Significance': 'Yes' if is_significant else 'No'\n",
    "        })\n",
    "\n",
    "\n",
    "    results_df = pd.DataFrame(comparison_results)\n",
    "    print(\"\\n Summary of T-Test Results \")\n",
    "    print(results_df[['Comparison', 'Mean_G1', 'Mean_G2', 'P_Value', 'Significance']])\n",
    "    # \n",
    "    \n",
    "    return results_df\n",
    "\n",
    "significance_results = check_significance(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d67357-6312-4658-b475-f24e8d95f512",
   "metadata": {},
   "source": [
    "#### 2.4: Finalizing and Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee530142-44d3-4b3d-b5be-88d15b34ddfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'location_summary.csv' and 'significance_results.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Reset index of location_summary for clean CSV export\n",
    "location_summary = location_summary.reset_index()\n",
    "\n",
    "# Save the necessary dataframes for Phase 3\n",
    "location_summary.to_csv('location_summary.csv', index=False)\n",
    "significance_results.to_csv('significance_results.csv', index=False)\n",
    "\n",
    "print(\"Results saved to 'location_summary.csv' and 'significance_results.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060badcb-09d4-4543-9ce5-56d8455c2cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
